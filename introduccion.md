# ¿Qué es computación en la nube?:

Fundamentalmente, la computación en la nube es la entrega de recursos de TI bajo demanda a través de Internet, con un modelo de precios de pago por uso. Esto significa que, en vez de invertir en la compra y el mantenimiento costoso de tus propios servidores físicos y centros de datos, puedes acceder a una amplia gama de servicios tecnológicos *(como capacidad de cómputo, almacenamiento, bases de datos y funcionalidades de red)* exactamente cuando los necesitas y desde cualquier lugar con conexión a Internet. Estos servicios son ofrecidos por empresas especializadas, como Amazon Web Services (AWS), que gestionan toda la infraestructura física subyacente.

Una característica esencial de este modelo es la disponibilidad bajo demanda y el acceso amplio a través de la red. Puedes provisionar o liberar recursos casi instantáneamente con unos pocos clics, sin los largos procesos de adquisición y configuración de hardware que implicaría la infraestructura tradicional. Además, el modelo de pago por uso es transformador: solo incurres en costos por los recursos que efectivamente consumes y durante el tiempo que los utilizas, de manera similar a una factura de servicios públicos. Esto elimina la necesidad de realizar grandes inversiones iniciales en hardware que podría quedar subutilizado.

Los recursos de TI que se pueden obtener de la nube son variados y cubren prácticamente cualquier necesidad tecnológica. Esto incluye desde servidores virtuales (cómputo) que ejecutan tus aplicaciones, hasta diversos tipos de sistemas de almacenamiento para tus datos, bases de datos gestionadas para organizar y consultar información eficientemente, y servicios de red para conectar y asegurar tus aplicaciones. Lo crucial es que, como usuario, te abstraes de la complejidad de la gestión del hardware físico; el proveedor de la nube se encarga del mantenimiento, las actualizaciones, la seguridad física y la operatividad de toda esa infraestructura.

Este paradigma ofrece beneficios significativos. La agilidad es uno de los más destacados, permitiendo a las empresas innovar y lanzar nuevas aplicaciones o servicios mucho más rápidamente. La elasticidad y escalabilidad son inherentes, lo que significa que puedes ajustar la cantidad de recursos que utilizas de forma dinámica, aumentándolos para picos de demanda o disminuyéndolos en periodos de baja actividad, optimizando así los costos. Precisamente, esta optimización de costos se manifiesta al cambiar de un modelo de gastos de capital (CAPEX), donde se realizan grandes inversiones iniciales, a un modelo de gastos operativos (OPEX), donde los costos son variables y se basan en el consumo real. Finalmente, al delegar la pesada carga de la gestión de infraestructura al proveedor de la nube, las organizaciones pueden enfocar sus recursos y esfuerzos en sus objetivos de negocio principales y en el desarrollo de valor para sus clientes, en lugar de en el mantenimiento de la infraestructura tecnológica.

# IaaS vs PaaS vs SaaS:
### IaaS (Infrastructure as a Service - Infraestructura como Servicio):
Imagina que quieres hacer pizza, pero no quieres comprar un horno, ni preocuparte por la conexión de gas o electricidad. Con IaaS, el proveedor de la nube te da el "horno" (servidores virtuales), el "espacio de cocina" (almacenamiento) y las "conexiones" (redes). Tú eres responsable de traer tus propios ingredientes (el sistema operativo), la receta (tus aplicaciones) y de cocinar la pizza (gestionar el software y los datos).
En términos técnicos, IaaS te proporciona los bloques de construcción fundamentales de la infraestructura de TI: servidores virtuales (como EC2 en AWS), almacenamiento en red (como EBS) y capacidades de red (como VPC). El proveedor de la nube gestiona el hardware físico subyacente (los centros de datos, los servidores físicos, el almacenamiento físico, la red física y la capa de virtualización). Tú, como usuario, eres responsable de instalar y gestionar el sistema operativo, el middleware (como servidores de aplicaciones o bases de datos que instales tú mismo), tus aplicaciones y tus datos. Este modelo te ofrece la mayor flexibilidad y control sobre tu infraestructura, similar a tener tus propios servidores, pero sin la necesidad de comprarlos y mantenerlos físicamente. Es ideal si necesitas un control granular, tienes aplicaciones heredadas que requieren configuraciones específicas del sistema operativo, o deseas migrar tus sistemas existentes a la nube con cambios mínimos.

### PaaS (Platform as a Service - Plataforma como Servicio):
Con PaaS es como si pidieras una pizza a domicilio. El restaurante (proveedor de la nube) se encarga del horno, los ingredientes, la preparación y la cocción. Tú solo necesitas tener los platos y las bebidas listos para comerla en casa (desarrollar y desplegar tu aplicación sobre la plataforma que te dan).
Técnicamente, PaaS elimina la necesidad de que gestiones la infraestructura subyacente (hardware, sistemas operativos, parches) y te permite enfocarte en el desarrollo, despliegue y gestión de tus aplicaciones. El proveedor de la nube no solo gestiona la infraestructura física y la virtualización (como en IaaS), sino también el sistema operativo, el middleware (como bases de datos gestionadas, colas de mensajes, motores de ejecución de código) y las herramientas de desarrollo. Tú solo te preocupas por tu código y tus datos. Ejemplos de servicios PaaS incluyen AWS Elastic Beanstalk (para desplegar aplicaciones web), AWS RDS (para bases de datos gestionadas) o Heroku. PaaS es ideal para desarrolladores que quieren acelerar el ciclo de vida del desarrollo de software sin preocuparse por la administración de la infraestructura, el sistema operativo o las actualizaciones de software de la plataforma.

### SaaS (Software as a Service - Software como Servicio):
SaaS es como ir a comer a un restaurante de pizzas. El restaurante (proveedor de la nube) se encarga de todo: el local, el horno, los ingredientes, la preparación, la cocción, los platos, las bebidas y hasta de limpiar después. Tú simplemente llegas, te sientas, pides tu pizza y la disfrutas.
En el mundo de la TI, SaaS te proporciona un producto de software completo, listo para usar, que es gestionado y operado por el proveedor del servicio. Accedes a la aplicación a través de Internet, generalmente mediante un navegador web o una aplicación móvil, y sueles pagar una suscripción. El proveedor de la nube se encarga de absolutamente todo: la infraestructura, el sistema operativo, la plataforma, la aplicación misma y su mantenimiento. Tú, como usuario final, simplemente utilizas el software. Ejemplos comunes de SaaS son Gmail, Salesforce, Microsoft 365 o Dropbox. La principal ventaja es la conveniencia y la reducción de la carga de gestión, ya que no necesitas instalar, mantener ni actualizar nada. Simplemente usas el servicio.

# Public vs Private vs Hybrid Cloud
### Nube Pública (Public Cloud):
Esto sería como usar el transporte público, como un autobús o un metro. El autobús es propiedad de una empresa de transporte (el proveedor de la nube, como AWS, Azure o Google Cloud) y es compartido por muchos pasajeros (múltiples clientes u "inquilinos"). Tú pagas por tu billete (los recursos que consumes) y te beneficias de una infraestructura masiva y bien mantenida sin tener que comprar el autobús tú mismo.
En términos técnicos, una Nube Pública es aquella donde los servicios de computación (servidores, almacenamiento, redes, etc.) son propiedad de un proveedor de servicios en la nube externo y se ofrecen al público general o a un amplio grupo de industrias a través de Internet. La infraestructura es compartida por múltiples organizaciones (multi-tenant). Los clientes pagan solo por los recursos que utilizan, beneficiándose de la enorme escala, la resiliencia y la amplia gama de servicios que estos proveedores pueden ofrecer. AWS es el ejemplo paradigmático de un proveedor de nube pública. Las principales ventajas son la escalabilidad casi ilimitada, el pago por uso, la ausencia de mantenimiento de hardware y la alta disponibilidad ofrecida por los grandes proveedores. La principal consideración suele ser la seguridad y la conformidad para datos muy sensibles, aunque los proveedores públicos invierten masivamente en seguridad.

### Nube Privada (Private Cloud):
Una Nube Privada sería como tener tu propio coche. Tú eres el dueño del coche (la infraestructura de la nube), lo mantienes y decides quién puede usarlo (solo tu organización). Tienes control total sobre él, pero también eres responsable de todos los costos y el mantenimiento.
Una Nube Privada consiste en recursos de computación en la nube que son utilizados exclusivamente por una única empresa u organización. Esta infraestructura puede estar ubicada físicamente en el centro de datos local de la organización (on-premises) o ser alojada por un proveedor externo, pero los recursos son dedicados y no compartidos. La Nube Privada ofrece un mayor nivel de control y seguridad sobre los datos y la infraestructura, lo que puede ser crucial para empresas con requisitos estrictos de cumplimiento normativo, seguridad o soberanía de datos. Aunque proporciona los beneficios de la nube (como la autosuficiencia y la escalabilidad dentro de sus límites), la organización es responsable de la compra, el mantenimiento y la gestión de la infraestructura, lo que puede implicar mayores costos iniciales y una menor elasticidad en comparación con la nube pública.

### Nube Híbrida (Hybrid Cloud):
la Nube Híbrida sería como usar tu propio coche para una parte del trayecto y luego tomar el transporte público para otra. Por ejemplo, conduces hasta una estación de tren y luego tomas el tren al centro de la ciudad. Combina lo mejor de ambos mundos según tus necesidades.
Una Nube Híbrida es una combinación de una o más nubes públicas con una o más nubes privadas (o infraestructura tradicional on-premises), que permanecen como entidades únicas pero están unidas por tecnología estandarizada o propietaria que permite la portabilidad de datos y aplicaciones entre ellas. Este modelo permite a las organizaciones aprovechar los beneficios de la nube pública (como la escalabilidad y el costo-eficiencia para cargas de trabajo no sensibles) mientras mantienen las aplicaciones y datos críticos o sensibles en un entorno de nube privada para mayor control y seguridad. Por ejemplo, una empresa podría usar la nube pública para desarrollar y probar nuevas aplicaciones, para picos de demanda (cloud bursting), o para recuperación ante desastres, mientras mantiene sus bases de datos de clientes en su nube privada. La Nube Híbrida ofrece flexibilidad y optimización de recursos, pero su gestión puede ser más compleja debido a la necesidad de integrar y orquestar entornos diferentes.

# Introducción a AWS:
AWS se lanzó comercialmente en 2006. Su origen se encuentra en la infraestructura interna desarrollada por Amazon para soportar sus propias operaciones de comercio electrónico a gran escala. La compañía identificó que esta infraestructura robusta, escalable y eficiente podría ser externalizada y ofrecida como un conjunto de servicios a otras empresas y desarrolladores. Los primeros servicios clave incluyeron Amazon S3 (Simple Storage Service) para el almacenamiento de objetos y Amazon EC2 (Elastic Compute Cloud) para la capacidad de cómputo virtualizada. Desde su lanzamiento, AWS ha experimentado una expansión continua, tanto en la diversidad de servicios ofrecidos como en su alcance geográfico global.

### Propuesta de Valor y Características Clave:
- Amplitud y Profundidad del Portafolio de Servicios: AWS se distingue por la vasta cantidad y la funcionalidad detallada de sus servicios, superando los 200. Esto permite a los usuarios construir arquitecturas complejas y soluciones sofisticadas que aborden una multiplicidad de casos de uso, desde aplicaciones web simples hasta sistemas de análisis de big data y cargas de trabajo de aprendizaje automático.
- Escalabilidad y Elasticidad: La plataforma está diseñada para permitir a los clientes escalar sus recursos de TI hacia arriba (aumentando la capacidad de los recursos existentes) o hacia afuera (añadiendo más instancias de recursos) de manera dinámica, en respuesta a la demanda. De igual forma, permite reducir los recursos cuando ya no son necesarios, optimizando así los costos.
- Modelo de Precios de Pago por Uso: Los clientes pagan únicamente por los servicios y la cantidad de recursos que consumen, durante el tiempo que los utilizan, sin necesidad de contratos a largo plazo o inversiones iniciales significativas en hardware. Existen modelos de precios alternativos, como las instancias reservadas o los Savings Plans, que ofrecen descuentos a cambio de compromisos de uso a plazo.
- Alcance Global: AWS opera una infraestructura global compuesta por Regiones y Zonas de Disponibilidad distribuidas geográficamente. Esto permite a los clientes desplegar aplicaciones más cerca de sus usuarios finales para reducir la latencia, cumplir con requisitos de soberanía de datos y diseñar arquitecturas de alta disponibilidad y tolerancia a fallos.
- Innovación Continua: AWS mantiene un ritmo acelerado de lanzamiento de nuevos servicios y características, respondiendo a las demandas del mercado y a los avances tecnológicos. Esto permite a los clientes acceder a tecnologías de vanguardia sin tener que desarrollarlas internamente.
- Seguridad: AWS prioriza la seguridad y ofrece un conjunto robusto de servicios y funcionalidades para proteger la infraestructura y los datos de los clientes. La seguridad en la nube opera bajo un modelo de responsabilidad compartida, donde AWS es responsable de la seguridad de la nube (infraestructura física, software de virtualización) y el cliente es responsable de la seguridad en la nube (configuración de servicios, gestión de identidades y accesos, cifrado de datos).

### Componentes Fundamentales (Introductorios):
Si bien la plataforma es extensa, algunos servicios son considerados fundamentales y son la base para muchas arquitecturas en AWS:
- Servicios de Cómputo: Incluyen Amazon EC2 (servidores virtuales), AWS Lambda (ejecución de código sin gestión de servidores) y servicios de contenedores como Amazon ECS y EKS.
- Servicios de Almacenamiento: Comprenden Amazon S3 (almacenamiento de objetos escalable), Amazon EBS (volúmenes de almacenamiento en bloque para EC2) y Amazon Glacier (almacenamiento de archivo de bajo costo).
- Servicios de Bases de Datos: Ofrecen opciones como Amazon RDS (bases de datos relacionales gestionadas), Amazon DynamoDB (base de datos NoSQL gestionada) y Amazon Redshift (almacén de datos).
- Servicios de Redes: Incluyen Amazon VPC (Virtual Private Cloud para aislar recursos en una red virtual), Amazon Route 53 (servicio de DNS), AWS Direct Connect (conexión dedicada) y Elastic Load Balancing (distribución de tráfico).
- Servicios de Seguridad, Identidad y Cumplimiento: Destaca AWS IAM (Identity and Access Management para controlar el acceso a los recursos de AWS).

# Infraesructura global de AWS:
La infraestructura global de Amazon Web Services está diseñada y construida para ofrecer la máxima flexibilidad, seguridad, fiabilidad y escalabilidad. Se basa en un concepto jerárquico de ubicaciones físicas que trabajan conjuntamente para proporcionar los servicios en la nube. Los componentes principales de esta infraestructura son las Regiones, las Zonas de Disponibilidad (Availability Zones o AZs) y los Puntos de Presencia (Edge Locations).

Una Región de AWS es un área geográfica física separada en el mundo donde AWS agrupa sus centros de datos. Cada Región es completamente independiente de las demás en términos de ubicación, energía, refrigeración y conectividad de red. Esta independencia asegura que si una Región experimenta un problema, las otras Regiones no se vean afectadas, lo que permite a los clientes diseñar arquitecturas resilientes y con tolerancia a fallos distribuyendo sus aplicaciones y datos en múltiples Regiones. Cuando se lanza un recurso en AWS, se elige la Región donde residirá. La elección de la Región suele basarse en factores como la proximidad a los usuarios finales para minimizar la latencia, los requisitos de soberanía de datos (algunas leyes exigen que los datos residan dentro de fronteras geográficas específicas), el costo de los servicios (que puede variar ligeramente entre Regiones) y la disponibilidad de servicios específicos (aunque la mayoría de los servicios principales están disponibles en todas las Regiones, los servicios más nuevos pueden lanzarse inicialmente en Regiones seleccionadas).

Dentro de cada Región de AWS, existen múltiples ubicaciones aisladas conocidas como Zonas de Disponibilidad (AZs). Una Zona de Disponibilidad consiste en uno o más centros de datos discretos, cada uno con energía, refrigeración y redes redundantes, y alojados en instalaciones separadas. Las AZs dentro de una misma Región están conectadas entre sí mediante enlaces de red de alta velocidad y baja latencia, pero están físicamente separadas por una distancia significativa (típicamente varios kilómetros) para protegerlas de desastres localizados como incendios, inundaciones o fallos de energía que pudieran afectar a una única ubicación. Este diseño permite a los clientes construir aplicaciones altamente disponibles: al desplegar instancias y datos en múltiples AZs dentro de una Región, una aplicación puede seguir funcionando incluso si una AZ completa falla. La mayoría de los servicios de AWS que requieren alta disponibilidad están diseñados para operar o replicarse a través de múltiples AZs.

Finalmente, AWS también opera una red de Puntos de Presencia (Edge Locations), que son centros de datos más pequeños distribuidos globalmente, mucho más numerosos que las Regiones y las AZs. Estos Puntos de Presencia se utilizan principalmente por dos servicios clave: Amazon CloudFront y Amazon Route 53. CloudFront es el servicio de red de entrega de contenido (CDN) de AWS, que almacena en caché copias del contenido (como videos, imágenes y archivos estáticos) más cerca de los usuarios finales para acelerar la entrega y reducir la latencia. Route 53 es el servicio de Sistema de Nombres de Dominio (DNS) de AWS, que traduce nombres de dominio legibles por humanos en direcciones IP. Al utilizar los Puntos de Presencia, estos servicios pueden responder a las solicitudes de los usuarios desde la ubicación más cercana, mejorando el rendimiento y la experiencia del usuario. Además de estos, AWS también tiene Cachés de Borde Regionales (Regional Edge Caches), que son ubicaciones más grandes que los Puntos de Presencia, situadas entre los servidores de origen y los Puntos de Presencia, para almacenar en caché contenido con menos frecuencia de acceso pero que sigue siendo popular, mejorando aún más el rendimiento de CloudFront.

# Modelo de responsabilidad compartida:
El Modelo de Responsabilidad Compartida define claramente qué aspectos de la seguridad son responsabilidad de AWS y cuáles son responsabilidad del cliente. Es fundamental entender esta división para asegurar que las cargas de trabajo y los datos desplegados en AWS estén debidamente protegidos. AWS se refiere a esto como la seguridad "de" la nube versus la seguridad "en" la nube.

AWS es responsable de la seguridad "de" la nube. Esto significa que AWS se encarga de proteger la infraestructura física y de red que ejecuta todos los servicios ofrecidos en la nube de AWS. Esto incluye el hardware, el software, las redes y las instalaciones físicas que componen los centros de datos globales de AWS. Específicamente, AWS gestiona y controla los componentes desde la capa de virtualización hasta la seguridad de las instalaciones físicas donde residen los servicios. Las responsabilidades de AWS en este ámbito incluyen la protección de la infraestructura global (Regiones, Zonas de Disponibilidad, Puntos de Presencia), la seguridad física de los centros de datos, la red subyacente que conecta los servicios, y el hipervisor que permite la virtualización. AWS se asegura de que esta infraestructura sea robusta, resiliente y esté protegida contra amenazas.

El cliente es responsable de la seguridad "en" la nube. La responsabilidad del cliente varía significativamente dependiendo de los servicios de AWS que elija y cómo los configure. En general, el cliente es responsable de gestionar y asegurar sus datos, incluyendo su clasificación y cumplimiento normativo; la configuración del sistema operativo (si utiliza servicios IaaS como EC2), los parches de seguridad y las actualizaciones; la gestión de la red y las configuraciones de firewall dentro de su entorno virtual (por ejemplo, Security Groups y Network ACLs en VPC); la gestión de identidades y accesos (utilizando servicios como AWS IAM para controlar quién puede acceder a qué recursos y con qué permisos); y la configuración de la seguridad a nivel de aplicación. El cliente también es responsable del cifrado de sus datos, tanto en tránsito como en reposo, utilizando las herramientas y servicios que AWS proporciona o soluciones de terceros.

La naturaleza exacta de la responsabilidad del cliente cambia según el tipo de servicio utilizado (IaaS, PaaS, SaaS). Por ejemplo, si un cliente utiliza Amazon EC2 (un servicio IaaS), es responsable de la gestión del sistema operativo invitado, de cualquier software de aplicación o utilidades instaladas por el cliente en las instancias, y de la configuración del firewall a nivel de sistema operativo, además de la configuración de los Security Groups proporcionados por AWS. En cambio, si un cliente utiliza un servicio gestionado como Amazon S3 (almacenamiento) o Amazon RDS (bases de datos gestionadas), AWS se encarga de la gestión del sistema operativo subyacente y la infraestructura de la plataforma, y el cliente se centra en la gestión de sus datos, los permisos de acceso a esos datos y la configuración de las opciones de seguridad específicas del servicio (como el cifrado de los buckets de S3 o las reglas de acceso a las bases de datos RDS).

# Well-Architected Framework
El AWS Well-Architected Framework es un conjunto de mejores prácticas, principios de diseño y preguntas guía desarrolladas por AWS a partir de la experiencia acumulada trabajando con miles de clientes. Su propósito principal es ayudar a los arquitectos de la nube a construir infraestructuras seguras, de alto rendimiento, resilientes y eficientes para sus aplicaciones y cargas de trabajo. No se trata de un servicio específico, sino de una guía metodológica y un enfoque consistente para evaluar arquitecturas y tomar decisiones de diseño informadas en la plataforma AWS.

El framework se estructura en torno a varios pilares fundamentales, cada uno de los cuales representa un área crítica que debe considerarse al diseñar cualquier sistema en la nube. Originalmente eran cinco pilares, y más recientemente se ha añadido un sexto. Estos pilares son:

### Excelencia Operacional (Operational Excellence): 
Este pilar se centra en la capacidad de ejecutar y monitorizar sistemas para entregar valor de negocio y mejorar continuamente los procesos y procedimientos de soporte. Implica la automatización de cambios, la respuesta a eventos y la definición de estándares para gestionar las operaciones diarias de manera eficiente. Se busca realizar operaciones como código, anotar toda la infraestructura, anticipar fallos y refinar frecuentemente los procedimientos operativos.

### Seguridad (Security): 
Este pilar aborda la protección de la información, los sistemas y los activos, al tiempo que se entrega valor de negocio mediante la evaluación de riesgos y la implementación de estrategias de mitigación. Incluye principios como implementar una base de identidad sólida, habilitar la trazabilidad, aplicar seguridad en todas las capas, automatizar las mejores prácticas de seguridad y proteger los datos en tránsito y en reposo.

### Fiabilidad (Reliability): 
Este pilar se enfoca en la capacidad de un sistema para recuperarse de fallos de infraestructura o servicios, adquirir dinámicamente recursos informáticos para satisfacer la demanda y mitigar las interrupciones, como configuraciones incorrectas o problemas transitorios de red. Los principios clave incluyen probar los procedimientos de recuperación, escalar horizontalmente para aumentar la disponibilidad agregada del sistema, detener la predicción de capacidad y gestionar el cambio mediante la automatización.

### Eficiencia del Rendimiento (Performance Efficiency): 
Este pilar se centra en el uso eficiente de los recursos informáticos para satisfacer los requisitos del sistema y mantener esa eficiencia a medida que la demanda cambia y las tecnologías evolucionan. Implica seleccionar los tipos y tamaños de recursos adecuados en función de los requisitos de la carga de trabajo, monitorizar el rendimiento y tomar decisiones informadas para mantener la eficiencia a medida que las necesidades empresariales evolucionan. Se promueve experimentar con más frecuencia, utilizar arquitecturas sin servidor y considerar diseños mecánicamente comprensivos.

### Optimización de Costos (Cost Optimization): 
Este pilar trata de la capacidad de evitar o eliminar gastos innecesarios o subóptimos. Incluye la comprensión y el control de dónde se gasta el dinero, la selección de los tipos de recursos más apropiados y rentables, el análisis del gasto a lo largo del tiempo y el escalado para satisfacer las necesidades del negocio sin sobreaprovisionar. Se fomenta la adopción de un modelo de consumo, la medición de la eficiencia general y el cese del gasto en el trabajo pesado indiferenciado del centro de datos.

### Sostenibilidad (Sustainability): 
Este es el pilar más reciente y se enfoca en minimizar los impactos ambientales de ejecutar cargas de trabajo en la nube. Aborda la reducción del consumo de energía y la mejora de la eficiencia en todo el ciclo de vida de la carga de trabajo, desde el diseño y la selección de hardware en los centros de datos de AWS hasta el desarrollo y despliegue de código por parte del cliente. Fomenta la comprensión del impacto, el establecimiento de objetivos de sostenibilidad, la maximización de la utilización, la anticipación y adopción de nuevas ofertas de hardware y software más eficientes, y el uso de servicios gestionados.
